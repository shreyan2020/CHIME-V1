{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "geographic-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "from rpy2.robjects import r as R\n",
    "%load_ext rpy2.ipython\n",
    "import sqlite3\n",
    "from cdt.causality.pairwise import CDS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from graphviz import Source\n",
    "from spellchecker import SpellChecker\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "physical-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(inp):\n",
    "    for pair in itertools.combinations(inp.items(), 2):\n",
    "        yield dict(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apparent-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, include_part=False, include_shape=False):\n",
    "    if include_part:\n",
    "        df['part'] = df['part'].replace(np.nan,'')\n",
    "        df['primary_concept'] =  df['part']+ ','+df['primary_concept']\n",
    "        df['primary_concept'] = df['primary_concept'].str.strip(',')\n",
    "        df['primary_concept'] = df['primary_concept'].replace(',','_of_',regex=True)\n",
    "    \n",
    "    df = df.drop(columns=['part'])\n",
    "    temp = df.replace('',np.nan)\n",
    "    if include_shape:\n",
    "        data = pd.get_dummies(temp, prefix=['primary_concept','color','shape'], columns=['primary_concept','colors','shapes'])\n",
    "    else:\n",
    "        data = pd.get_dummies(temp, prefix=['primary_concept','color'], columns=['primary_concept','colors'])\n",
    "        \n",
    "    data['y'] = pd.to_numeric(data['y'])\n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "automotive-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_graph(df):\n",
    "    g = nx.DiGraph()\n",
    "    for idx, row in df.iterrows():\n",
    "        n1 = row['pair1']\n",
    "        n2 = row['pair2']\n",
    "        if row['causal'] > 0:\n",
    "            if n1 == 'y':\n",
    "                # print('y>0')\n",
    "                g.add_edge(n2,n1)\n",
    "            else:\n",
    "                g.add_edge(n1,n2)\n",
    "        elif row['causal'] < 0:\n",
    "            if n2 == 'y':\n",
    "                print('y<0')\n",
    "                g.add_edge(n1,n2)\n",
    "            else:\n",
    "                g.add_edge(n2,n1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "banned-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_inference(data, filename_dot, G):\n",
    "    results = []\n",
    "    for col in G.nodes():\n",
    "        if col =='y' or col=='\\\\n':\n",
    "            continue\n",
    "        # print(col)\n",
    "        model=CausalModel(\n",
    "                data = data,\n",
    "                treatment=col,\n",
    "                outcome='y',\n",
    "                graph=filename_dot,\n",
    "                missing_nodes_as_confounders=False\n",
    "        )\n",
    "        identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "        estimate = model.estimate_effect(identified_estimand,\n",
    "                                        method_name=\"backdoor.linear_regression\",\n",
    "                                        control_value=0,\n",
    "                                        treatment_value=1,\n",
    "                                        confidence_intervals=False,\n",
    "                                        test_significance=False)\n",
    "\n",
    "        tmp = {'treatment':col,'score':str(estimate.value)}\n",
    "        # print('values',tmp)\n",
    "        results.append(tmp)\n",
    "    newlist = sorted(results, key=lambda d: d['score'],reverse=True)\n",
    "    res = pd.DataFrame.from_dict(newlist)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "digital-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mediation(data, filename_dot, G):\n",
    "    results = []\n",
    "    for col in G.nodes():\n",
    "        if col =='y' or col=='\\\\n':\n",
    "            continue\n",
    "        tmp = {}\n",
    "        # print(col)\n",
    "        tmp['primary_concept'] = col\n",
    "        model=CausalModel(\n",
    "                data = data,\n",
    "                treatment=col,\n",
    "                outcome='y',\n",
    "                graph=filename_dot,missing_nodes_as_confounders=False)\n",
    "\n",
    "        identified_estimand_nde = model.identify_effect(estimand_type=\"nonparametric-nde\",\n",
    "                                            proceed_when_unidentifiable=True)\n",
    "        identified_estimand_nie = model.identify_effect(estimand_type=\"nonparametric-nie\",\n",
    "                                            proceed_when_unidentifiable=True)\n",
    "        mediator = identified_estimand_nde.get_mediator_variables()\n",
    "        \n",
    "        causal_estimate_nde = model.estimate_effect(identified_estimand_nde,\n",
    "                                        method_name=\"mediation.two_stage_regression\",\n",
    "                                        confidence_intervals=False,\n",
    "                                        test_significance=False,\n",
    "                                        method_params = {\n",
    "                                            'first_stage_model': dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator,\n",
    "                                            'second_stage_model': dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator\n",
    "                                        }\n",
    "                                        )\n",
    "        tmp['nde'] = causal_estimate_nde.value\n",
    "        if tmp['nde'] is None:\n",
    "            continue\n",
    "        med =mediator[0] if len(mediator)>0 else ''\n",
    "        if len(mediator) > 0:\n",
    "            tmp['mediator'] = med\n",
    "            causal_estimate_nie = model.estimate_effect(identified_estimand_nie,\n",
    "                                        method_name=\"mediation.two_stage_regression\",\n",
    "                                        confidence_intervals=False,\n",
    "                                        test_significance=False,\n",
    "                                        method_params = {\n",
    "                                            'first_stage_model': dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator,\n",
    "                                            'second_stage_model': dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator\n",
    "                                        }\n",
    "                                        )\n",
    "            tmp['nie'] = causal_estimate_nie.value\n",
    "            tmp['total'] = float(tmp['nie']) + float(tmp['nde'])\n",
    "            tmp['mediation_proportion'] = float(tmp['nie'])/tmp['total']\n",
    "            \n",
    "        else:\n",
    "            tmp['mediator'] = np.nan\n",
    "            tmp['total'] = tmp['nde']\n",
    "            tmp['mediation_proportion'] = np.nan\n",
    "            tmp['nie'] = np.nan\n",
    "        # print(tmp['total'])\n",
    "        results.append(tmp)\n",
    "    newlist = sorted(results, key=lambda d: d['total'],reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in glob.glob('class_concepts_images/*.csv'):\n",
    "    graph_file = str('cds_obj_color_shape/graphs/'+os.path.basename(file_name)[:-4] + '.dot')\n",
    "    result_file = str('cds_obj_color_shape/effects/'+os.path.basename(file_name))\n",
    "    print(result_file)\n",
    "    if not glob.glob(result_file):\n",
    "        \n",
    "        print(graph_file)\n",
    "        df = pd.read_csv(file_name)\n",
    "        data, _ = get_data(df)\n",
    "        t = list(pairwise(data))\n",
    "        tmp = pd.DataFrame([(list(i.items())[0][0],list(i.items())[1][0],np.array(list(i.items())[0][1]),np.array(list(i.items())[1][1])) for i in t], \n",
    "                       columns=['pair1','pair2','A','B'])\n",
    "\n",
    "        obj = CDS()\n",
    "        output = obj.predict(tmp[['A','B']])\n",
    "        tmp['causal'] = output\n",
    "        tmp = tmp[tmp.causal!=0]\n",
    "        samples = int(len(tmp)*0.25)\n",
    "        sliced_df = pd.concat([tmp.head(samples), tmp.tail(samples)])\n",
    "        G = gen_graph(sliced_df)\n",
    "        if not glob.glob(graph_file):\n",
    "            nx.drawing.nx_pydot.write_dot(G,graph_file)\n",
    "        res = causal_inference(data, graph_file, G)\n",
    "        res.to_csv(result_file,index=False)\n",
    "    print(graph_file,result_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
